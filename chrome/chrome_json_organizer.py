#!/usr/bin/env python3
"""
Chrome JSON ãƒ–ãƒƒã‚¯ãƒãƒ¼ã‚¯æ•´ç†ãƒ„ãƒ¼ãƒ«ï¼ˆWSLå¯¾å¿œï¼‰
Windows11ã®Chromeãƒ–ãƒƒã‚¯ãƒãƒ¼ã‚¯JSONãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç›´æ¥è§£æãƒ»æ•´ç†

ä½¿ç”¨æ–¹æ³•:
python chrome_json_organizer.py
"""

import json
import urllib.request
import urllib.parse
from datetime import datetime
from collections import defaultdict
import sys
import os

class ChromeJSONBookmarkOrganizer:
    def __init__(self, json_file=None):
        if json_file is None:
            # Windows Chrome ã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ‘ã‚¹ï¼ˆWSLçµŒç”±ï¼‰
            self.json_file = "/mnt/c/Users/itoh/AppData/Local/Google/Chrome/User Data/Default/Bookmarks"
        else:
            self.json_file = json_file
            
        self.bookmarks = []
        self.duplicates = []
        self.broken_links = []
        self.categories = defaultdict(int)
        
    def parse_bookmarks(self):
        """Chromeã®JSONãƒ–ãƒƒã‚¯ãƒãƒ¼ã‚¯ãƒ•ã‚¡ã‚¤ãƒ«ã‚’è§£æ"""
        try:
            with open(self.json_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
        except Exception as e:
            print(f"ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
            return False
            
        self._extract_bookmarks(data['roots'], "")
        print(f"ç·ãƒ–ãƒƒã‚¯ãƒãƒ¼ã‚¯æ•°: {len(self.bookmarks)}")
        return True
        
    def _extract_bookmarks(self, node, folder_path):
        """å†å¸°çš„ã«ãƒ–ãƒƒã‚¯ãƒãƒ¼ã‚¯ã‚’æŠ½å‡º"""
        if isinstance(node, dict):
            if node.get('type') == 'url':
                # ãƒ–ãƒƒã‚¯ãƒãƒ¼ã‚¯ã‚¢ã‚¤ãƒ†ãƒ 
                bookmark = {
                    'url': node.get('url', ''),
                    'name': node.get('name', ''),
                    'folder': folder_path,
                    'date_added': node.get('date_added', ''),
                    'date_last_used': node.get('date_last_used', ''),
                    'guid': node.get('guid', '')
                }
                self.bookmarks.append(bookmark)
                self._categorize_bookmark(bookmark)
                
            elif node.get('type') == 'folder' and 'children' in node:
                # ãƒ•ã‚©ãƒ«ãƒ€
                folder_name = node.get('name', 'ç„¡é¡Œãƒ•ã‚©ãƒ«ãƒ€')
                new_path = f"{folder_path}/{folder_name}" if folder_path else folder_name
                
                for child in node['children']:
                    self._extract_bookmarks(child, new_path)
                    
            elif 'children' in node:
                # ãƒ«ãƒ¼ãƒˆãƒ¬ãƒ™ãƒ«ã®ã‚³ãƒ³ãƒ†ãƒŠ
                for child in node['children']:
                    self._extract_bookmarks(child, folder_path)
                    
        elif isinstance(node, list):
            for item in node:
                self._extract_bookmarks(item, folder_path)
                
        # ç‰¹åˆ¥ãªã‚­ãƒ¼å‡¦ç†
        for key in ['bookmark_bar', 'other', 'synced']:
            if key in node:
                folder_name = {
                    'bookmark_bar': 'ãƒ–ãƒƒã‚¯ãƒãƒ¼ã‚¯ãƒãƒ¼',
                    'other': 'ãã®ä»–ã®ãƒ–ãƒƒã‚¯ãƒãƒ¼ã‚¯', 
                    'synced': 'åŒæœŸã•ã‚ŒãŸãƒ–ãƒƒã‚¯ãƒãƒ¼ã‚¯'
                }.get(key, key)
                
                new_path = f"{folder_path}/{folder_name}" if folder_path else folder_name
                self._extract_bookmarks(node[key], new_path)
                
    def _categorize_bookmark(self, bookmark):
        """ãƒ–ãƒƒã‚¯ãƒãƒ¼ã‚¯ã‚’ã‚«ãƒ†ã‚´ãƒªåˆ†é¡"""
        url = bookmark['url'].lower()
        name = bookmark['name'].lower()
        
        # æ—¥æœ¬èªã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚‚å«ã‚ãŸåˆ†é¡
        if any(word in url or word in name for word in [
            'github', 'git', 'stackoverflow', 'qiita', 'zenn', 'tech', 'dev', 'code', 'programming',
            'ãƒ—ãƒ­ã‚°ãƒ©ãƒ ', 'é–‹ç™º', 'ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢', 'ã‚³ãƒ¼ãƒ‰'
        ]):
            self.categories['é–‹ç™ºãƒ»ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°'] += 1
            
        elif any(word in url or word in name for word in [
            'youtube', 'video', 'netflix', 'amazon prime', 'niconico', 'tiktok',
            'å‹•ç”»', 'ãƒ‹ã‚³ãƒ‹ã‚³', 'ãƒ†ãƒ¬ãƒ“', 'ã‚¢ãƒ‹ãƒ¡', 'æ˜ ç”»'
        ]):
            self.categories['å‹•ç”»ãƒ»ã‚¨ãƒ³ã‚¿ãƒ¼ãƒ†ã‚¤ãƒ¡ãƒ³ãƒˆ'] += 1
            
        elif any(word in url or word in name for word in [
            'news', 'nikkei', 'asahi', 'mainichi', 'yomiuri', 'nhk', 'cnn', 'bbc',
            'ãƒ‹ãƒ¥ãƒ¼ã‚¹', 'æ–°è', 'æœæ—¥', 'èª­å£²', 'æ¯æ—¥', 'æ—¥çµŒ'
        ]):
            self.categories['ãƒ‹ãƒ¥ãƒ¼ã‚¹ãƒ»æƒ…å ±'] += 1
            
        elif any(word in url or word in name for word in [
            'amazon', 'rakuten', 'yahoo', 'shop', 'buy', 'cart', 'price', 'sale',
            'æ¥½å¤©', 'ã‚·ãƒ§ãƒƒãƒ—', 'è³¼å…¥', 'è²·ã„ç‰©', 'é€šè²©', 'ãƒ¨ãƒ‰ãƒã‚·', 'ãƒ“ãƒƒã‚¯ã‚«ãƒ¡ãƒ©'
        ]):
            self.categories['ã‚·ãƒ§ãƒƒãƒ”ãƒ³ã‚°'] += 1
            
        elif any(word in url or word in name for word in [
            'twitter', 'facebook', 'instagram', 'linkedin', 'social', 'line',
            'ãƒ„ã‚¤ãƒƒã‚¿ãƒ¼', 'ãƒ•ã‚§ã‚¤ã‚¹ãƒ–ãƒƒã‚¯', 'ã‚¤ãƒ³ã‚¹ã‚¿', 'ãƒ©ã‚¤ãƒ³', 'SNS'
        ]):
            self.categories['SNSãƒ»ã‚½ãƒ¼ã‚·ãƒ£ãƒ«'] += 1
            
        elif any(word in url or word in name for word in [
            'bank', 'money', 'finance', 'pay', 'card', 'investment', 'stock',
            'éŠ€è¡Œ', 'ãƒãƒãƒ¼', 'ãŠé‡‘', 'æŠ•è³‡', 'æ ª', 'ã‚«ãƒ¼ãƒ‰', 'é‡‘è', 'SBI', 'JCB'
        ]):
            self.categories['é‡‘èãƒ»ãƒãƒãƒ¼'] += 1
            
        elif any(word in url or word in name for word in [
            'google', 'gmail', 'drive', 'docs', 'office', 'microsoft', 'tool', 'utility',
            'ãƒ„ãƒ¼ãƒ«', 'ã‚ªãƒ•ã‚£ã‚¹', 'ã‚°ãƒ¼ã‚°ãƒ«', 'ãƒã‚¤ã‚¯ãƒ­ã‚½ãƒ•ãƒˆ'
        ]):
            self.categories['ãƒ„ãƒ¼ãƒ«ãƒ»ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£'] += 1
            
        elif any(word in url or word in name for word in [
            'study', 'learn', 'education', 'course', 'tutorial', 'wiki', 'doc',
            'å­¦ç¿’', 'å‹‰å¼·', 'æ•™è‚²', 'ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«', 'ã‚¦ã‚£ã‚­', 'è¾æ›¸'
        ]):
            self.categories['å­¦ç¿’ãƒ»æ•™è‚²'] += 1
            
        else:
            self.categories['ãã®ä»–'] += 1
            
    def find_duplicates(self):
        """é‡è¤‡ãƒ–ãƒƒã‚¯ãƒãƒ¼ã‚¯ã‚’æ¤œå‡º"""
        url_count = defaultdict(list)
        name_count = defaultdict(list)
        
        for i, bookmark in enumerate(self.bookmarks):
            url_count[bookmark['url']].append(i)
            name_count[bookmark['name']].append(i)
            
        # URLé‡è¤‡
        url_duplicates = {url: indices for url, indices in url_count.items() if len(indices) > 1}
        
        # åå‰é‡è¤‡ï¼ˆURLãŒç•°ãªã‚‹å ´åˆï¼‰
        name_duplicates = {}
        for name, indices in name_count.items():
            if len(indices) > 1 and name:  # ç©ºã®åå‰ã¯é™¤å¤–
                urls = [self.bookmarks[i]['url'] for i in indices]
                if len(set(urls)) > 1:  # ç•°ãªã‚‹URLã§åŒã˜åå‰
                    name_duplicates[name] = indices
                    
        self.duplicates = {
            'url_duplicates': url_duplicates,
            'name_duplicates': name_duplicates
        }
        
        print(f"URLé‡è¤‡: {len(url_duplicates)}çµ„")
        print(f"åå‰é‡è¤‡: {len(name_duplicates)}çµ„")
        
    def check_broken_links(self, max_check=50, timeout=3):
        """ãƒªãƒ³ã‚¯åˆ‡ã‚Œã‚’ãƒã‚§ãƒƒã‚¯ï¼ˆåˆ¶é™ä»˜ãï¼‰"""
        print(f"ãƒªãƒ³ã‚¯åˆ‡ã‚Œãƒã‚§ãƒƒã‚¯ä¸­ï¼ˆæœ€å¤§{max_check}ä»¶ï¼‰...")
        
        # HTTPSãƒªãƒ³ã‚¯ã®ã¿ã‚’ãƒã‚§ãƒƒã‚¯
        http_bookmarks = [(i, b) for i, b in enumerate(self.bookmarks) 
                         if b['url'].startswith(('http://', 'https://'))]
        
        check_count = min(len(http_bookmarks), max_check)
        broken_count = 0
        
        for idx, (i, bookmark) in enumerate(http_bookmarks[:check_count]):
            if idx % 10 == 0:
                print(f"é€²è¡ŒçŠ¶æ³: {idx}/{check_count}")
                
            try:
                request = urllib.request.Request(bookmark['url'])
                request.add_header('User-Agent', 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36')
                
                with urllib.request.urlopen(request, timeout=timeout) as response:
                    if response.getcode() >= 400:
                        self.broken_links.append({
                            'index': i,
                            'url': bookmark['url'],
                            'name': bookmark['name'],
                            'error': f"HTTP {response.getcode()}"
                        })
                        broken_count += 1
                        
            except Exception as e:
                self.broken_links.append({
                    'index': i,
                    'url': bookmark['url'],
                    'name': bookmark['name'],
                    'error': str(e)[:100]  # ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’çŸ­ç¸®
                })
                broken_count += 1
                
        print(f"ãƒªãƒ³ã‚¯åˆ‡ã‚Œ: {broken_count}ä»¶")
        
    def display_analysis(self):
        """åˆ†æçµæœã‚’è¡¨ç¤º"""
        print("\n" + "="*60)
        print("ğŸ“Š ãƒ–ãƒƒã‚¯ãƒãƒ¼ã‚¯åˆ†æçµæœ")
        print("="*60)
        
        print(f"\nğŸ“Œ ç·ãƒ–ãƒƒã‚¯ãƒãƒ¼ã‚¯æ•°: {len(self.bookmarks)}")
        
        print(f"\nğŸ”„ é‡è¤‡çŠ¶æ³:")
        print(f"  â€¢ URLé‡è¤‡: {len(self.duplicates.get('url_duplicates', {}))}çµ„")
        print(f"  â€¢ åå‰é‡è¤‡: {len(self.duplicates.get('name_duplicates', {}))}çµ„")
        
        if self.broken_links:
            print(f"\nâŒ ãƒªãƒ³ã‚¯åˆ‡ã‚Œ: {len(self.broken_links)}ä»¶")
            
        print(f"\nğŸ“ ã‚«ãƒ†ã‚´ãƒªåˆ¥åˆ†é¡:")
        sorted_categories = sorted(self.categories.items(), key=lambda x: x[1], reverse=True)
        for category, count in sorted_categories:
            percentage = (count / len(self.bookmarks)) * 100
            print(f"  â€¢ {category}: {count}ä»¶ ({percentage:.1f}%)")
            
        # ãƒ•ã‚©ãƒ«ãƒ€åˆ¥çµ±è¨ˆ
        folder_count = defaultdict(int)
        for bookmark in self.bookmarks:
            folder = bookmark['folder'] or 'æœªåˆ†é¡'
            folder_count[folder] += 1
            
        print(f"\nğŸ“‚ ãƒ•ã‚©ãƒ«ãƒ€åˆ¥çµ±è¨ˆï¼ˆä¸Šä½10å€‹ï¼‰:")
        sorted_folders = sorted(folder_count.items(), key=lambda x: x[1], reverse=True)[:10]
        for folder, count in sorted_folders:
            print(f"  â€¢ {folder}: {count}ä»¶")
            
    def display_duplicates_detail(self):
        """é‡è¤‡ã®è©³ç´°è¡¨ç¤º"""
        if not self.duplicates.get('url_duplicates'):
            return
            
        print(f"\nğŸ”„ URLé‡è¤‡è©³ç´°ï¼ˆä¸Šä½10çµ„ï¼‰:")
        url_dupes = list(self.duplicates['url_duplicates'].items())[:10]
        
        for url, indices in url_dupes:
            print(f"\n  URL: {url[:80]}...")
            for idx in indices:
                bookmark = self.bookmarks[idx]
                print(f"    â€¢ {bookmark['name']} ({bookmark['folder']})")
                
    def generate_report(self):
        """ãƒ¬ãƒãƒ¼ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ç”Ÿæˆ"""
        report = {
            'analysis_date': datetime.now().isoformat(),
            'total_bookmarks': len(self.bookmarks),
            'categories': dict(self.categories),
            'duplicates_count': {
                'url_duplicates': len(self.duplicates.get('url_duplicates', {})),
                'name_duplicates': len(self.duplicates.get('name_duplicates', {}))
            },
            'broken_links_count': len(self.broken_links),
            'top_folders': {}
        }
        
        # ãƒ•ã‚©ãƒ«ãƒ€çµ±è¨ˆ
        folder_count = defaultdict(int)
        for bookmark in self.bookmarks:
            folder = bookmark['folder'] or 'æœªåˆ†é¡'
            folder_count[folder] += 1
        report['top_folders'] = dict(sorted(folder_count.items(), key=lambda x: x[1], reverse=True)[:20])
        
        report_file = f"chrome_analysis_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(report, f, ensure_ascii=False, indent=2)
            
        print(f"\nğŸ“„ è©³ç´°ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜: {report_file}")
        return report_file

def main():
    print("ğŸ” Windows11 Chrome ãƒ–ãƒƒã‚¯ãƒãƒ¼ã‚¯åˆ†æé–‹å§‹")
    print("-" * 60)
    
    organizer = ChromeJSONBookmarkOrganizer()
    
    if not organizer.parse_bookmarks():
        return
        
    print("\nğŸ”„ é‡è¤‡æ¤œå‡ºä¸­...")
    organizer.find_duplicates()
    
    print("\nâŒ ãƒªãƒ³ã‚¯åˆ‡ã‚Œãƒã‚§ãƒƒã‚¯ä¸­...")
    organizer.check_broken_links()
    
    organizer.display_analysis()
    organizer.display_duplicates_detail()
    
    report_file = organizer.generate_report()
    
    print(f"\nâœ… åˆ†æå®Œäº†ï¼")

if __name__ == "__main__":
    main()